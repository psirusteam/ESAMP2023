---
title: "Desagregación de Estimaciones en Áreas Pequeñas un enfoque bayesiano"
subtitle: ""
date: "CEPAL - Unidad de Estadísticas Sociales"
format: beamer
Email: andres.gutierrez@cepal.org
---

```{r setup, include=FALSE}
library(printr)
library(ggplot2)
library(magrittr)
library(survey)
library(srvyr)
library(convey)
library(TeachingSampling)
library(printr)
library(furrr)
library(purrr)
library(tidyr)
library(knitr)
library(kableExtra)
library(bayesplot) 
library(posterior)
library(patchwork)

select <- dplyr::select

#knitr::opts_chunk$set(eval = FALSE)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,
                      cache = TRUE)
ggplot2::theme_set(theme_bw())
options(digits = 4)

tba <- function(dat, cap = NA){
 kable(dat,
      format = "latex", digits =  4,
      caption = cap) %>% 
     kable_styling(bootstrap_options = "striped", full_width = F)%>%
         kable_classic(full_width = F)
}

```


```{r echo=FALSE, out.width = "500px", out.height="250px",fig.align='center'}
include_graphics("www/F_01_ODS.PNG")
```


# Algunas metas del ODS2 (Hambre cero)

De aquí a 2030, poner fin al hambre y asegurar el acceso de
todas las personas, en particular los pobres y las personas en
situaciones de vulnerabilidad, incluidos los niños menores de 1
año, a una alimentación sana, nutritiva y suficiente durante
todo el año.

  - Prevalencia de la subalimentación.
  
  - Prevalencia de la inseguridad alimentaria moderada o grave en 
   la población, según la Escala de Experiencia de Inseguridad Alimentaria.


# Algunas metas del ODS8 (Empleo decente)


De aquí a 2030, lograr el empleo pleno y productivo y el
trabajo decente para todas las mujeres y los hombres, incluidos
los jóvenes y las personas con discapacidad, así como la
igualdad de remuneración por trabajo de igual valor.

  -   Tasa de desempleo, desglosada por sexo, edad y personas con
discapacidad.


# Principio fundamental de la desagregación de datos

  Los indicadores de los Objetivos de Desarrollo Sostenible
  deberán desglosarse, siempre que sea pertinente, por ingreso,
  sexo, edad, raza, etnicidad, estado migratorio, discapacidad
  y ubicación geográfica, u otras características, de conformidad
  con los Principios Fundamentales de las Estadísticas Oficiales.

**Resolución de la Asamblea General - 68/261**

# Limitaciones de las encuestas. 

# ¿Qué es el coeficiente de variación?

El coeficiente de variación es una medida de error relativo a un
estimador, se define como:

$$
cve\left(\hat{\theta}\right)=\frac{se\left(\hat{\theta}\right)}{\hat{\theta}}
$$

Muchas veces se expresa como un porcentaje, aunque no está
acotado a la derecha, y por eso es conveniente a la hora de hablar
de la precisión de una estadística que viene de una encuesta.


# Estándares de alerta en algunos países (encuestas de hogares)


```{r echo=FALSE, out.width = "400px", out.height="250px",fig.align='center', fig.cap= "Alertas sobre los coeficientes de variación"}
include_graphics("www/F_02_cve.PNG")
```

# Algunas alertas definidas en la publicación

Cuando se sobrepasa el umbral del coeficiente de variación aparecen algunas de las siguientes alertas:

  -   No se publica
  
  -   Usar con precaución.
  
  -   Las estimaciones requieren revisiones, no son precisas y se deben usar con precaución.
  
  -   Poco confiable, menos preciso. 
  
  -   No cumple con los estándares de publicación. 
  
  -   Con reserva, referencial, cuestionable. 

  -   Valores muy aleatorios, estimación pobre.


# Dominios de estudio y subpoblaciones de interés

Una encuesta se planea con el fin de generar información precisa y
confiable en los dominios de estudio que se han predefinido. Sin
embargo, existen subgrupos poblacionales que la encuesta no abordó
en su diseño, y sobre los cuales se quisiera una mayor precisión.

  -   Incidencia de la pobreza desagregado por departamento o provincia (tamaño de muestra conocido y planificado).
  
  -   Tasa de desocupación desagregada por sexo (tamaño de muestra aleatorio, pero planificado).
  
  -   Tasa de asistencia neta estudiantil en primaria desagregada por quintiles de ingreso (tamaño de muestra aleatorio).


# Precisión de los estimadores

Debido a que una encuesta es una investigación parcial sobre una
población finita, es necesario saber que:

  -   A partir de una encuesta, no se calculan indicadores, sino que se estiman con ayuda de los datos de la encuesta.
  
  -   Es necesario calcular el grado de error que se comete al no poder realizar una investigación exhaustiva. Este error es conocido como el error de muestreo.
  
  -   La precisión de un estimador está supeditada al intervalo de confianza.


Entre más angosto sea el intervalo, más precisión se genera y por
ende se tiene un menor error de muestreo.

# El tamaño de muestra efectivo

  -   En las encuestas de hogares, con diseños de muestreo complejos, no existe una sucesión de variables que sean independientes e identicamente distribuidas.
  
  -   La muestra $y_{1},\dots,y_{n}$ no es un vector en el espacio n-dimensional, donde se asume que cada componente del vector puede variar por sí mismo.
  
  -   La dimensión final del vector ($y_{1},\dots,y_{n}$) es mucho menor que n, puesto que existe una forma jerárquica en la selección de los hogares y a la interrelación de la variable de interés con las UPMs


# El tamaño de muestra efectivo

El tamaño de muestra efectivo se define como sigue:
$$
n_{efectivo}=\frac{n}{Deff}
$$

En donde Deff es el efecto de diseño que depende de: _1._ El número
de encuestas promedio que se realizaron en cada UPM. _2._ La
correlación existente entre la variable de interés y las mismas UPMs.

Es posible considerar que, si el tamaño de muestra efectivo no es
mayor a un umbral, entonces la cifra no debería ser considerada
para publicación.


# Grados de libertad

En las subpoblaciones los grados de libertad no se consideran fijos
sino variables.

$$
gl=\sum_{h=1}^{H}v_{h}\times\left(n_{Ih}-1\right)
$$

Note que $ν_h$ es una variable indicadora que toma el valor uno si el
estrato $h$ contiene uno o mas casos de la subpoblación de interés,
$n_{Ih}$ es el número de UPMs en el estrato. En el caso más general, los
grados de libertad se reducen a la siguiente expresión:


          gl = #UPMs − #Estrato



# Uso de métodos SAE

# Justificación

  -   Los estimadores directos, basados solo en unidades de muestreo observadas para cada área pequeña, no son suficientemente confiables.
  
  -   Tamaño de muestra pequeño o incluso ninguna unidad observada (falta de información).
  
  -   El coeficiente de variación (CV) es demasiado alto para el indicador objetivo a nivel de área.
  
# Incremento del coeficiente de variación 

```{r echo=FALSE, out.width = "400px", out.height="250px",fig.align='center', fig.cap= "Distribución de los coeficientes de variación en Chile"}
include_graphics("www/F_03_incremento_cv.PNG")
```

# Justificación

Cuando los estimadores directos no son confiables para algunos dominios de interés, existen dos opciones:

  1 Sobremuestreo: aumentar el tamaño de la muestra en los dominios de interés (aumento de los costos).
  
  2 Aplicar técnicas estadísticas que permitan estimaciones confiables en esos dominios, métodos SAE.

# ¿Qué es un área pequeña?

  -   La mayoría de las encuestas nacionales están planificadas para entregar estimaciones confiables a nivel nacional y regional pero a niveles más bajos se reduce la precisión.
  
  -   Un área pequeña es un dominio para el cual el tamaño de muestra específico no es suficientemente grande para obtener estimaciones confiables.
  
  -   Habitualmente son dominios no planificados y su tamaño de muestra esperado es aleatorio y es más grande a medida que aumenta el tamaño de la población del área.


# ¿Qué es un área pequeña?

La subpoblación de interés puede ser una zona geográfica o subgrupos socioeconómicos.

  -   Geográfico: provincias, áreas del mercado de trabajo, municipios, sectores censales para medir por ejemplo la tasa de desempleo a nivel comunal.
  
  -   Dominio de subgrupos específicos: edad × sexo × raza dentro del ámbito geográfico de una zona, para medir por ejemplo la tasa de desempleo por sexo o edad específica en las zonas urbanas.

# Algunos métodos

  -   Los estimadores SAE se dividen en dos tipos principales
dependiendo de cómo se aplican los modelos a los datos dentro
de las áreas pequeñas: nivel de área y nivel de unidad.

  -   Los estimadores de área pequeña se basan en cálculos de nivel
de área si los modelos vinculan la variable de interés y con
variables auxiliares x específicas del área.


# Algunos métodos

  -   Se llaman modelos a nivel de unidad si se vinculan valores individuales para las variables auxiliares específicas de la unidad.
  
  -   Los estimadores basados en áreas pequeñas se calculan a nivel de área si los datos de la unidad no están disponibles.
  
  -   También pueden ser calculados si los datos de nivel de unidad están disponibles resumiéndolos en el nivel de área apropiado.

# Proceso de estimación

```{r echo=FALSE, out.width = "400px", out.height="250px",fig.align='center', fig.cap= "Producción de estadísticas con SAE"}
include_graphics("www/F_04_flujo_sae.PNG")
```

# Consideraciones

  -   Todos los métodos SAE requieren datos auxiliares a nivel del área pequeña desde el cual toman prestada la fuerza. 
  
  -   La efectividad de los métodos SAE depende del grado de asociación entre la variable de interés y los datos auxiliares. 
  
  -   La búsqueda de buenas variables auxiliares es crítica, incluida la construcción imaginativa de tales variables.
  
  -   Los datos auxiliares deben medirse de manera consistente a través de las áreas pequeñas, pero pueden incluir estimaciones de muestras grandes con error de muestreo conocido.

# Desafíos

  -   Aumento de las tasas de no respuesta.

  -   Aumento de costos, menos financiación.

  -   Aumento de la demanda de estimaciones para dominios pequeños como por raza, etnia o pobreza.

  -   Aumento de la demanda de estimaciones de áreas pequeñas.

  -   Aumento de la complejidad en los contenidos de los cuestionarios y por lo tanto la carga de respuesta.
  
  -   Aumento de la demanda de análisis secundarios, uso público y archivos de datos de uso restringido.
  


#  Función Generalizada de Varianza (FGV)

# ¿Cuál es la importancia de la Función Generalizada de Varianza?

  -   La varianza del estimador directo es un insumo crucial en el modelo de áreas.

  -   No es posible calcular la varianza del estimador directo a nivel de dominio.
  
  -   En dominios con un tamaño de muestra muy pequeño, las estimaciones de varianza pueden ser poco fiables.
  
  -   Se sugiere la utilidad de un modelo de suavizamiento de las varianzas.
  
  - El propósito del suavizamiento es eliminar el ruido y la volatilidad en las estimaciones de varianza para obtener una señal más precisa del proceso.

# La Función Generalizada de Varianza

Hidiroglou (2019) establece que:  $E_{\mathscr{MP}}\left(\hat{\theta}^{dir}_d\right)=\boldsymbol{x}^{T}_{d}\boldsymbol{\beta}$ y $V_{\mathscr{MP}}\left(\hat{\theta}^{dir}_d\right)=\sigma_{u}^2+\tilde{\sigma}^2_{d}$, en donde el subíndice  $\mathscr{MP}$ hace referencia a la inferencia doble que se debe tener en cuenta en este tipo de ajustes.

-   $\mathscr{M}$ hace referencia a la medida de probabilidad inducida por el modelamiento y la inclusión de las covariables auxiliares ($\boldsymbol{x}_{d}$).

-   $\mathscr{P}$ hace referencia a la medida de probabilidad inducida por el diseño de muestreo complejo que induce las estimaciones directas. 

# Estimación de la Varianza de Muestreo  

La FGV consiste en ajustar un modelo log-lineal a la varianza directa estimada. Partiendo del hecho de que se tiene acceso a un estimador insesgado de $\sigma^2$, denotado por $\hat{\sigma}^2$ se tiene que:
$$
E_{\mathscr{MP}}\left(\hat{\sigma}_{d}^{2}\right)=E_{\mathscr{M}}\left(E_{\mathscr{P}}\left(\hat{\sigma}_{d}^{2}\right)\right)=E_{\mathscr{M}}\left(\sigma_{d}^{2}\right)=\tilde{\sigma}_{d}^{2}
$$

La anterior igualdad puede interpretarse como que un estimador insesgado y simple de $\tilde{\sigma}_{d}^{2}$ puede ser $\hat{\sigma}_{d}^{2}$. 

# Modelos de Suavizamiento  

Rivest y Belmonte (2000) proponen modelos de suavizamiento para estimar las varianzas directas. Estos modelos se definen de la siguiente manera:

$$
\log\left(\hat{\sigma}_{d}^{2}\right)=\boldsymbol{z}_{d}^{T}\boldsymbol{\alpha}+\boldsymbol{\varepsilon}_{d}
$$

En donde $\boldsymbol{z}_{d}$ es un vector de covariables explicativas que son funciones de $\boldsymbol{x}_{d}$, $\boldsymbol{\alpha}$ es un vector de parámetros que deben ser estimados, $\boldsymbol{\varepsilon}_{d}$ son errores aleatorios con media cero y varianza constante, que se asumen idénticamente distribuidos condicionalmente sobre $\boldsymbol{z}_{d}$. 

# Estimación Suavizada 

-   La estimación suavizada de la varianza de muestreo está dada por:

$$
\tilde{\sigma}_{d}^{2}=E_{\mathscr{MP}}\left(\sigma_{d}^{2}\right)=\exp\left(\boldsymbol{z}_{d}^{T}\boldsymbol{\alpha}\right)\times\Delta
$$

  En donde, $E_{\mathscr{MP}}\left(\varepsilon_{d}\right)=\Delta$.

-   Haciendo uso del método de los momentos, se tiene el siguiente estimador insesgado para $\Delta$: 
$$
\hat{\Delta}=\frac{\sum_{d=1}^{D}\hat{\sigma}_{d}^{2}}{\sum_{d=1}^{D}\exp\left(\boldsymbol{z}_{d}^{T}\boldsymbol{\alpha}\right)}
$$

# Estimación de parámetros 

-   La estimación del coeficiente de parámetros de regresión está dada por la siguiente expresión:

$$
\hat{\boldsymbol{\alpha}}=\left(\sum_{d=1}^{D}\boldsymbol{z}_{d}\boldsymbol{z}_{d}^{T}\right)^{-1}\sum_{d=1}^{D}\boldsymbol{z}_{d}\log\left(\hat{\sigma}_{d}^{2}\right)
$$

-   Y el estimador suavizado de la varianza muestral está definido por:

$$
\hat{\tilde{\sigma}}_{d}^{2}=\exp\left(\boldsymbol{z}_{d}^{T}\hat{\boldsymbol{\alpha}}\right)\hat{\Delta}
$$

# Datos: Gran Encuesta Integrada de Hogares (GEIH) de Colombia. 

La Gran Encuesta Integrada de Hogares (GEIH) del 2018 en Colombia, utilizó un diseño muestral complejo que incluyó la estratificación de la población en zonas urbanas y rurales, junto con un muestreo por conglomerados. La muestra seleccionada fue significativa, permitiendo la recolección de datos de manera representativa en todo el país. En total, se utilizaron 98,000 Unidades Primarias de Muestreo (UPM) para tener estadísticas confiables a Nivel Nacional, Regiones Geográficas, Ciudades principales y Áreas Urbanas/Rurales, Estratos Socioeconómicos.

# Set de datos 

```{r,echo=FALSE}
tabla1 <- readRDS("www/01_FGV/01_tabla_encuesta.rds")
tba(tabla1, cap = "GEIH Colombia")
```

# Diseño muestral 

Para definir el diseño muestral a partir de una base de datos de encuesta se usan las librerías `survey` y `srvyr`.  

```{r, eval=FALSE}
library(survey)
library(srvyr)
options(survey.lonely.psu = "adjust")

diseno <-
  as_survey_design(
    ids = upm,
    weights = wkx,
    strata = estrato,
    nest = TRUE,
    .data = encuesta
  )
```

# Estimaciones directas por dominio 

Para la estimación directa de la proporción se emplea la función `direct.supr`, disponible en el archivo [`0Source_FH.R`](https://github.com/psirusteam/2023COLsae/tree/main/Recursos/D%C3%ADa2/Sesion1/0Recursos). Está función realiza las estimaciones y criterios de calidad en una encuesta de muestreo complejo con diseño estratificado y por conglomerados.

```{r, eval=FALSE}
directodam2 <- direct.supr(design.base = diseno,
                             variable = pobreza, 
                             group = dam2,
                             upm = upm,
                             estrato = estrato)
```

# Dominios seleccionados 

-   Mínimo 50 observaciones por dominio. 

-   Efecto de diseño (Deff) mayor a 1.

-   Mínimo 3 grados de libertad. 

```{r,echo=FALSE}
tabla2 <- readRDS("www/01_FGV/02_tabla.rds")
tba(tabla2, cap = "Conteo de dominios seleccionados")
```

# FGV para la GEIH de Colombia 

Para este proceso se realiza la transformación $\log(\hat{\sigma}^2_d)$ y la selección de las columnas identificador del municipio (`dam2`), la estimación directa  (`pobreza`), el número de personas en el dominio (`nd`) y la varianza estimada (`vardir`). 

```{r, echo=FALSE}
tabla3 <- readRDS("www/01_FGV/03_tabla_FGV.rds") %>% head(5)
tba(tabla3, cap = "Set datos para la FGV")
```


# Analisis gráfico 

```{r echo=FALSE, out.width = "400px", out.height="250px",fig.align='center', fig.cap= "Diagramas de dispersión"}
include_graphics("www/01_FGV/04_fig_FGV.png")
```

# Modelo para la varianza

El modelo definido para el conjunto de datos es el siguiente.

$$
\log(\hat{\sigma}^2) = \hat{\theta}_{dir} + n_{d}^2 + \sqrt{\hat{\theta}_{dir}}
$$
El resultado del modelo se muestra a continuación: 

```{r, echo=FALSE}
library(gtsummary)
mod_fgv <- readRDS("www/01_FGV/05_tabla_modelo_FGV.rds")
tbl_regression(mod_fgv) %>% 
  add_glance_table(include = c(r.squared, adj.r.squared) ) %>% 
  modify_caption("Resumen del modelo")
```

# Estimación para $\Delta$ y predicción. 

A partir de la estimación del modelo se debe obtener el  valor de la constante $\Delta$ para lo cual se usa el siguiente código. 

```{r, eval=FALSE}
delta.hat = sum(baseFGV$vardir) / 
  sum(exp(fitted.values(FGV1)))
```

Por último se tiene la varianza suavizada. 

```{r, eval=FALSE}
hat.sigma <- 
  data.frame(
    dam2 = baseFGV$dam2,
    hat_var = delta.hat * exp(fitted.values(FGV1)))
```

# Validación de resultados. 

```{r echo=FALSE, out.width = "400px", out.height="250px",fig.align='center', fig.cap= "FGV y Varianza directa, por tamaño de muestra"}
include_graphics("www/01_FGV/07_fig_FGV_vs_vardir2.png")
```

# Modelos de área. 

# Modelo de Fay Herriot

- El Modelo de Fay Herriot, propuesto por Fay y Herriot en 1979, es ampliamente utilizado en la estimación de áreas pequeñas. Este enfoque estadístico se aplica cuando la información a nivel de individuo es limitada, pero se dispone de datos a nivel de áreas y de información auxiliar relacionada con estos datos.

- El modelo establece una relación entre los indicadores de las áreas, $\theta_d$, que varían en función de un vector de covariables $\boldsymbol{x}_d$. Se formula como $\theta_d = \boldsymbol{x}^{T}_{d}\boldsymbol{\beta} + u_d$, donde $u_d$ es un efecto aleatorio específico para cada área.

# Modelo de Fay Herriot  

- Dado que los valores reales de los indicadores $\theta_d$ no son observables, se utiliza el estimador directo $\hat{\theta}^{DIR}_d$ para estimarlos, lo que introduce un error de muestreo. Es decir, 

$$
\hat{\theta}_d^{DIR} = \theta + e_d  
$$

- El modelo se ajusta teniendo en cuenta el error de muestreo $e_d$, y las varianzas $\sigma^2_{e_d}$ se estiman a partir de los microdatos de la encuesta. Esto es: 


$$
\hat{\theta}^{DIR}_{d} = \boldsymbol{x}^{T}_{d}\boldsymbol{\beta} + u_d + e_d
$$.

# Modelo de Fay Herriot  

El mejor predictor lineal insesgado (BLUP) bajo el modelo Fay Herriot se calcula como $\tilde{\theta}_{d}^{FH}$, y se basa en el uso de $\gamma_d$ para ponderar adecuadamente el estimador directo y la información auxiliar, permitiendo una estimación más precisa de los indicadores en áreas pequeñas. Su ecuación esta dada por: 

$$
\tilde{\theta}_{d}^{FH} = \boldsymbol{x}^{T}{d}\tilde{\boldsymbol{\beta}}+\tilde{u}_{d}
$$,

donde $\tilde{u}_d = \gamma_d\left(\hat{\theta}^{DIR}_{d} - \boldsymbol{x}^{T}_{d}\tilde{\boldsymbol{\beta}} \right)$ y $\gamma_d=\frac{\sigma^2_u}{\sigma^2_u + \sigma^2_{e_d}}$.


# Modelo de área para la estimación de la pobreza {-}

Sea $P_d$ la probabilidad de encontrar una persona en condición de pobreza en el $d-$ésimo dominio de la población. Entonces, el estimador directo de $P_d$ se puede escribir como:  

$$
\hat{P}^{DIR}_{d} = P_d + e_d
$$

Ahora bien, $P_d$ se puede modelar de la siguiente manera,  

$$
P_d = \boldsymbol{x}^{T}_{d}\boldsymbol{\beta} + u_d
$$

# Modelo de área para la estimación de la pobreza

Reescribiendo $\hat{P}^{DIR}_{d}$ en términos de las dos ecuaciones anteriores tenemos:  

$$
\hat{P}^{DIR}_{d} = \boldsymbol{x}^{T}_{d}\boldsymbol{\beta} + u_d + e_d
$$

Ahora, es posible suponer que:

-   $\hat{P}^{DIR}_d \sim N(\boldsymbol{x}^{T}_{d}\boldsymbol \beta, \sigma_u^2 +\sigma_{e_d}^2)$,

-   $\hat{P}^{DIR}_d \mid u_d \sim N(\boldsymbol{x}^{T}_{d}\boldsymbol \beta + u_d,\sigma_{e_d}^2)$ y

-   $u_d \sim N(0, \sigma^2_u)$


# Distribuciones previas. 

Las distribuciones previas para $\boldsymbol{\beta}$ y $\sigma^2_u$

$$
\beta_p  \sim  N(0, 10000)
$$

$$
\sigma^2_u \sim  IG(0.0001, 0.0001)
$$

por tanto, el estimador bayesiano para $P_d$ esta dado como $\tilde{P}_d = E\left(P_d\mid\hat{P}_d^{DIR}\right)$


# Procedimiento de estimación de la pobreza en los municipios de colombia

Las covariables disponibles se muestran en la siguiente tabla, estas fueron obtenidas previamente.


```{r,echo=FALSE}
tabla1 <- readRDS("www/02_FH_Nornal/01_tabla_predictors.rds") %>% head(5)
tba(tabla1[,1:8], cap = "Covariables disponibles")
```

# Modelo de FH: Rutina en `STAN`

```
data {
  int<lower=0> N1; // number of data items
  int<lower=0> N2; // number of data items for prediction
  int<lower=0> p;  // number of predictors
  matrix[N1, p] X; // predictor matrix
  matrix[N2, p] Xs; // predictor matrix
  vector[N1] y;    // predictor matrix 
  vector[N1] sigma_e; // known variances
}

parameters {
  vector[p] beta;       // coefficients for predictors
  real<lower=0> sigma2_u;
  vector[N1] u;
}
```

# Modelo de FH: Rutina en `STAN`


```
transformed parameters{
  vector[N1] theta;
  vector[N1] thetaSyn;
  vector[N1] thetaFH;
  vector[N1] gammaj;
  real<lower=0> sigma_u;
  thetaSyn = X * beta;
  theta = thetaSyn + u;
  sigma_u = sqrt(sigma2_u);
  gammaj =  to_vector(sigma_u ./ (sigma_u + sigma_e));
  thetaFH = (gammaj) .* y + (1-gammaj).*thetaSyn; 
}

```

# Modelo de FH: Rutina en `STAN`
  
```
model {
  // likelihood
  y ~ normal(theta, sigma_e); 
  // priors
  beta ~ normal(0, 100);
  u ~ normal(0, sigma_u);
  sigma2_u ~ inv_gamma(0.0001, 0.0001);
}

generated quantities{
  vector[N2] y_pred;
  for(j in 1:N2) {
    y_pred[j] = normal_rng(Xs[j] * beta, sigma_u);
  }
}

```
  

# Preparando los insumos para `STAN`

-   Definir el modelo de área 

```{r}
formula_mod  <- formula(
  ~ sexo2 + anoest2 + anoest3 +
    anoest4 + edad2 + edad3  +  edad4  + edad5 + etnia1 +
    etnia2 + tasa_desocupacion + luces_nocturnas +
    cubrimiento_cultivo + alfabeta
)
```

# Preparando los insumos para `STAN`

-   Dividir la base de datos en dominios observados y no observados.
    
```{r, eval=FALSE}
# Dominios observados.
data_dir <- base_FH %>% filter(!is.na(pobreza))

Xdat <- model.matrix(formula_mod, data = data_dir)

# Dominios NO observados.
data_syn <-
  base_FH %>% anti_join(data_dir %>% select(dam2))

Xs <- model.matrix(formula_mod, data = data_syn)
```

# Preparando los insumos para `STAN`

-   Creando lista de parámetros para `STAN`

```{r, eval=FALSE}
sample_data <- list(
  N1 = nrow(Xdat),   # Observados.
  N2 = nrow(Xs),   # NO Observados.
  p  = ncol(Xdat),       # Número de regresores.
  X  = as.matrix(Xdat),  # Covariables Observados.
  Xs = as.matrix(Xs),    # Covariables NO Observados
  y  = as.numeric(data_dir$pobreza), # Estimación directa
  sigma_e = sqrt(data_dir$hat_var)   # Error de estimación
)
```

# Compilando el modelo en `STAN`

La forma de compilar el código de `STAN` desde R. 

```{r,eval=FALSE}
library(rstan)
fit_FH_normal <- "www/02_FH_Nornal/17FH_normal.stan"
options(mc.cores = parallel::detectCores())
model_FH_normal <- stan(
  file = fit_FH_normal,  
  data = sample_data,   
  verbose = FALSE,
  warmup = 500,         
  iter = 1000,            
  cores = 4              
)
saveRDS(object = model_FH_normal,
        file = "www/02_FH_Nornal/model_FH_normal.rds")
```

# Resultados del modelo para los dominios observados. 

Empleando la función `ppc_dens_overlay()`para graficar una comparación entre la distribución empírica de la variable observada pobreza en los datos y las distribuciones predictivas posteriores simuladas para la misma variable.

```{r, eval=FALSE}
y_pred_B <- as.array(model_FH_normal,
                     pars = "theta") %>%
  as_draws_matrix()

rowsrandom <- sample(nrow(y_pred_B), 100)

y_pred2 <- y_pred_B[rowsrandom,]

ppc_dens_overlay(y = as.numeric(data_dir$pobreza),
                 y_pred2)
```

# Chequeo Predictivo Posterior

```{r echo=FALSE, out.width = "400px", out.height="250px",  fig.cap= "PPC"}
knitr::include_graphics("www/02_FH_Nornal/02_Fig_FH1.png")
```

# Validacion de convengencia de cadenas $\sigma^2$

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "Convergencia de la cadena"}
knitr::include_graphics("www/02_FH_Nornal/03_Fig_FH2.png")
```

# Comparación de las estimaciones

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= ""}
knitr::include_graphics("www/02_FH_Nornal/04_Fig_FH3.png")
```

# Proceso de Benchmarking

- Del censo extraer el total de personas por DAM2 

```{r, echo=FALSE}
total_pp <- readRDS(file = "www/02_FH_Nornal/06_tabla_total_personas.rds")

N_dam_pp <- total_pp %>%   ungroup() %>%  
            mutate(dam_pp = sum(total_pp) ) 

tba(N_dam_pp %>% slice(1:10))
```

# Estimación directa 

Obtener las estimaciones directa por DAM o el nivel de agregación en el cual la encuesta es representativa.

```{r, eval=FALSE}
directoDam <- diseno %>% 
   group_by(Agregado = "Nacional") %>% 
  summarise(
    theta_dir = survey_mean(pobreza, vartype = c("ci"))
    )

```
```{r,echo=FALSE}
directoDam <- readRDS("www/02_FH_Nornal/07_tabla_estimacionDir.rds")
tba(directoDam)
```

# Calculo de ponderadores 

Luego de organizar la información anterior se realizaa el calculo de los pesos para el Benchmark

```{r, eval=FALSE}
estimacionesPre <-
  readRDS("www/02_FH_Nornal/05_tabla_estimacionesPre.rds")
temp <- estimacionesPre %>%
  inner_join(N_dam_pp) %>%
  mutate(theta_dir = directoDam$theta_dir)
R_dam2 <- temp %>%
  summarise(
    R_dam_RB = unique(theta_dir) /
      sum((total_pp  / dam_pp) * theta_pred))

```

```{r, echo=FALSE}
tabla_peso <-
  readRDS("www/02_FH_Nornal/08_tabla_peso.rds")
tba(tabla_peso)
```

# Estimación con el modelo de área despues del Benchmarking 

```{r, eval=FALSE}
pesos <- temp %>% 
  mutate(W_i = total_pp / dam_pp) %>% 
  select(dam2, W_i)

estimacionesBench <- estimacionesPre %>%
  mutate(R_dam_RB = R_dam2$R_dam_RB) %>%
  mutate(theta_pred_RBench = R_dam_RB * theta_pred) %>%
  select(dam, dam2, theta_pred, theta_pred_RBench)
```

```{r, echo=FALSE}
 estimacionesBench <- 
  readRDS("www/02_FH_Nornal/09_tabla_estimacionesBench.rds")
tba(estimacionesBench %>% slice(1:5))
```

# Validación de los resultados. 

Este código junta las estimaciones del modelo con pesos de benchmarking con los valores observados y sintéticos, y luego resume las estimaciones combinadas para compararlas con la estimación directa obtenida anteriormente. 

```{r, eval=FALSE}
temp <- estimacionesBench %>% 
  left_join(estimacionesPre) %>%
  summarise(
    thetaSyn = sum(W_i * thetaSyn),
    thetaFH = sum(W_i * theta_pred),
    theta_RBench = sum(W_i * theta_pred_RBench)
  ) %>%
  mutate(
    theta_dir = directoDam$theta_dir,
    theta_dir_low = directoDam$theta_dir_low,
    theta_dir_upp = directoDam$theta_dir_upp
  )
```
# Resultado de la Validación

```{r,echo=FALSE}
tabla_valida <- readRDS(
  "www/02_FH_Nornal//10_tabla_valida.rds")
tba(tabla_valida, cap = "Comparación de las estimaciones")
```

# 

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "Mapa de pobreza"}
knitr::include_graphics("www/02_FH_Nornal/11_Mapa_pobreza.PNG")
```


# Modelo de área: Transformación Arcoseno. 

-   En el modelo de Fay-Herriot, la combinación lineal de covariables puede generar valores que no están dentro del rango aceptable para una proporción.

   - Para abordar esto, se aplica una transformación arcoseno a los estimadores: $\hat{z}_d = arcsin\left( \sqrt{ \hat{\theta}_d} \right)$.

# Varianza de la Transformación Arcoseno

   - La varianza de la transformación arcoseno está relacionada con el factor de corrección DEFF y el tamaño de muestra efectivo:

$$Var\left( \hat{z}_d \right) = \frac{\widehat{DEFF}_d}{4\times n_d} = \frac{1}{4\times n_{d,efectivo} }$$.

# Especificación del Modelo de Fay-Herriot

   - El modelo de Fay-Herriot se define con una variable latente $Z_d$ que sigue una distribución normal.
   - La media de $Z_d$ ($\mu_d$) se relaciona con las covariables a través de $\boldsymbol{x}^{T}_{d}\boldsymbol{\beta} + u_d$.

   - La relación entre la variable latente $\theta_d$ y el estimador directo se establece como $\theta_d =  \left(sin(\mu_d)\right)^2$.

Lo anterior se simplifica como:

1. $Z_d \mid \mu_d,\sigma^2_d   \sim   N(\mu_d, \sigma^2_d)$
2. $\mu_d  =  \boldsymbol{x}^{T}_{d}\boldsymbol{\beta} + u_d$
3. $\theta_d  =   \left(sin(\mu_d)\right)^2$


# Distribuciones Previas

Se especifican distribuciones previas para los parámetros del modelo:
     - $\boldsymbol{\beta} \sim N\left(0,1000 \right)$
     - $\sigma_{u}^{2} \sim IG\left(0.0001,0.0001\right)$.

# Modelo de área: Rutina en `STAN` 

El código es similar al anterior, aquí se muestran las variaciones 
```
transformed parameters{
  vector[N1] theta;
  vector[N1] lp;
  real<lower=0> sigma_u;
  lp = X * beta + u;
  sigma_u = sqrt(sigma2_u);
  for(k in 1:N1){
    theta[k] = pow(sin(lp[k]), 2);
  }
}
```
# Modelo de FH: Rutina en `STAN` 

```

model {
  // likelihood
  y ~ normal(lp, sigma_e); 
  // priors
  beta ~ normal(0, 100);
  u ~ normal(0, sigma_u);
  sigma2_u ~ inv_gamma(0.0001, 0.0001);
}

```


# Procedimiento de estimación

Para la base preparada previamente hay que seleccionar y transformar las columnas de interés. 

```{r, eval=FALSE}
statelevel_predictors_df <- 
  readRDS("www/03_FH_Arcsin/statelevel_predictors.rds")
base_FH <- 
  readRDS("www/03_FH_Arcsin/base_FH_2018.rds") %>% 
  transmute(
    dam2,        # id dominios
    pobreza,
    T_pobreza = asin(sqrt(pobreza)),  # creando zd
    n_effec = n_eff_FGV,      # n efectivo
    varhat = 1/(4*n_effec)    # varianza para zd
    )
base_FH <- full_join(base_FH, 
           statelevel_predictors_df, by = "dam2" )
```

# Preparando los insumos para `STAN`

Selección de las covariables, que corresponden a las seleccionadas previamente. 

```{r, eval=FALSE} 
names_cov <- c(
  "sexo2" , "anoest2" , "anoest3",   "anoest4",
  "edad2" , "edad3" , "edad4" , "edad5" , "etnia1",
  "etnia2" ,  "tasa_desocupacion" , "luces_nocturnas" ,
  "cubrimiento_cultivo" , "alfabeta"
)
```

# Dividir el set de datos. 

El proceso de estimación y predicción se hace por separado dentro de `STAN`

-   Dominios observados.
```{r, eval=FALSE}
data_dir <- base_FH %>% filter(!is.na(T_pobreza))
Xdat <- cbind(inter = 1,data_dir[,names_cov])
```

-   Dominios NO observados.
```{r, eval=FALSE}
data_syn <-
  base_FH %>% anti_join(data_dir %>% select(dam2))
Xs <-  cbind(inter = 1,data_syn[,names_cov])
```

# Lista de parámetros para `STAN`

El motor de procesamiento de `STAN` se basa en `C++`, por lo que hace necesario que los argumentos para ejecutar los códigos ingresen en forma de lista. 

```{r, eval=FALSE}
sample_data <- list(
  N1 = nrow(Xdat),       # Observados.
  N2 = nrow(Xs),         # NO Observados.
  p  = ncol(Xdat),       # Número de regresores.
  X  = as.matrix(Xdat),  # Covariables Observados.
  Xs = as.matrix(Xs),    # Covariables NO Observados
  y  = as.numeric(data_dir$T_pobreza),
  sigma_e = sqrt(data_dir$varhat)
)
```

# Compilando el modelo en `STAN`
  
```{r, eval=FALSE}

fit_FH_arcoseno <- 
  "www/03_FH_Arcsin/15FH_arcsin_normal.stan"

model_FH_arcoseno <- stan(
  file = fit_FH_arcoseno,  
  data = sample_data,   
  verbose = FALSE,
  warmup = 500,         
  iter = 1000,            
  cores = 4              
)
saveRDS(model_FH_arcoseno,
        "www/03_FH_Arcsin/model_FH_arcoseno.rds")

```


# Resultados del modelo para los dominios observados. 

De forma similar al modelo de Fay Herrior se realiza el gráfico con el chequeo predictivo posterior. 


```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "PPC Arcosin"}
knitr::include_graphics("www/03_FH_Arcsin/01_Fig_FH_Asin.png")
```

# Análisis gráfico de la convergencia de las cadenas de $\sigma^2_u$. 

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "Recorrido de las cadenas"}
knitr::include_graphics("www/03_FH_Arcsin/02_Fig_FH_Asin2.png")
```

# Mapa de pobreza con transformación Arcosin 

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "Mapa de pobreza con transformación Arcosin"}
knitr::include_graphics("www/03_FH_Arcsin/03_Fig_Mapa_arcoseno.PNG")
```

# Mapa de los coeficientes de variación para la pobreza

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "Mapa de los coeficientes de variación"}
knitr::include_graphics("www/03_FH_Arcsin/04_Fig_Mapa_arcoseno_cv.PNG")
```

# Modelos de área con variable respuesta Beta.

- El modelo beta-logístico se introdujo inicialmente en el contexto de un enfoque de Estimación de Mejor Predicción (EBP) por Jiang y Lahiri en 2006. Fue utilizado para estimar medias de dominio en poblaciones finitas.

- El modelo área beta-logístico se define a través de la siguiente expresión:
    - $\hat{p}_{d} \mid P_d \sim beta(a_d, b_d)$.

  - La función de enlace se relaciona con los parámetros del modelo:
    - $logit(P_{d}) \mid \boldsymbol{\beta}, \sigma^2_u  \sim  N(\boldsymbol{x}_d^T\boldsymbol{\beta},\sigma^2_u)$.

# Estimación de Parámetros
  - Los parámetros $a_d$ y $b_d$ se estiman de la siguiente manera:
    - $a_d = P_d \times \phi_d$
    - $b_d = (1 - P_d) \times \phi_d$
  - Donde $\phi_d = \frac{n_d}{\widehat{DEFF}_d} -1 = n_{d,efectivo} -1$.

- Se especifican distribuciones previas para los parámetros del modelo:
    - $\beta_k \sim N(0, 10000)$
    - $\sigma^2_u \sim IG(0.0001, 0.0001)$.

# Modelo de área: Rutina en `STAN` 
En este bloque de código vemos la transformación que se realiza sobre los parámetros de entrada. 

```
transformed parameters{
  vector[N1] LP;
  real<lower=0> sigma_u;
  vector[N1] theta;           
  LP = X * beta + u;
  sigma_u = sqrt(sigma2_u); 
  for (i in 1:N1) { 
    theta[i] = inv_logit(LP[i]); 
  }
}

```
# Modelo de FH: Rutina en `STAN` 

```
model {
  // model calculations
  vector[N1] a;                       
  vector[N1] b;                       

  for (i in 1:N1) { 
    a[i] = theta[i] * phi[i];
    b[i] = (1 - theta[i]) * phi[i];
  }

  // priors
  beta ~ normal(0, 100);
  u ~ normal(0, sigma_u);
  sigma2_u ~ inv_gamma(0.0001, 0.0001);

  // likelihood
  y ~ beta(a, b);
}
```


# Procedimiento de estimación

En forma similar a los modelos anteriores hacemos uso de la base previamente preparada

```{r, eval=FALSE}
base_FH <-
readRDS("www/04_FH_Beta_y_Binomial/base_FH_2018.rds") %>%
  select(dam2, pobreza, n_eff_FGV)

base_FH <- full_join(base_FH,
             statelevel_predictors_df, by = "dam2")
```
Las covariables son las mismas que se emplearon en los modelos anteriores.  

# Dividir el set de datos. 

El proceso de estimación y predicción se hace por separado dentro de `STAN`

-   Dominios observados.
```{r, eval=FALSE}
data_dir <- base_FH %>% filter(!is.na(T_pobreza))
Xdat <- cbind(inter = 1,data_dir[,names_cov])
```

-   Dominios NO observados.
```{r, eval=FALSE}
data_syn <-
  base_FH %>% anti_join(data_dir %>% select(dam2))
Xs <-  cbind(inter = 1,data_syn[,names_cov])
```

# Lista de parámetros para `STAN`


```{r, eval=FALSE}
sample_data <- list(
  N1 = nrow(Xdat),   # Observados.
  N2 = nrow(Xs),   # NO Observados.
  p  = ncol(Xdat),       # Número de regresores.
  X  = as.matrix(Xdat),  # Covariables Observados.
  Xs = as.matrix(Xs),    # Covariables NO Observados
  y  = as.numeric(data_dir$pobreza),
  phi = data_dir$n_eff_FGV - 1 
)
```

# Compilando el modelo en `STAN`
  
```{r, eval=FALSE}

fit_FH_beta_logitic <-
  "www/04_FH_Beta_y_Binomial/16FH_beta_logitc.stan"

model_FH_beta_logitic <- stan(
  file = fit_FH_beta_logitic,  
  data = sample_data,   
  verbose = FALSE,
  warmup = 500,         
  iter = 1000,            
  cores = 4              
)
saveRDS(model_FH_beta_logitic, 
file = "www/04_FH_Beta_y_Binomial/model_FH_beta.rds")

```


# Resultados del modelo para los dominios observados. 


```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "PPC modelo de área Beta"}
knitr::include_graphics("www/04_FH_Beta_y_Binomial/01_Fig_ppc.png")
```

# Análisis gráfico de la convergencia de las cadenas de $\sigma^2_u$. 

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "Recorrido de las cadenas"}
knitr::include_graphics("www/04_FH_Beta_y_Binomial/02_Fig_sigma.png")
```

# Mapa de pobreza con modelo de área de respuesta beta. 

```{r echo=FALSE, out.width = "500px", out.height="250px", fig.cap= "Mapa de pobreza con el modelo de área de respuesta beta."}
knitr::include_graphics("www/04_FH_Beta_y_Binomial/03_Fig_Mapa_Beta.png")
```

# Mapa de los coeficientes de variación para la pobreza

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "Mapa de los coeficientes de variación"}
knitr::include_graphics("www/04_FH_Beta_y_Binomial/04_Fig_Mapa_Beta_cv.png")
```

# Modelos de área con variable respuesta Binomial. 

- El modelo de área de Fay-Herriot puede ser sustituido por un Modelo Mixto Lineal Generalizado (GLMM) cuando los datos observados son inherentemente discretos, como recuentos de personas u hogares con ciertas características.
  
- En un GLMM, se asume una distribución binomial para los datos $Y_d$ con probabilidad de éxito $\theta_d$ y un modelo logístico para $\theta_d$ con errores normales en la escala logit.

# Ecuación del modelo  
  
El modelo se formula de la siguiente manera:

  - $Y_d \mid \theta_d, n_d \sim Binomial(n_d, \theta_d)$
  - $logit\left(\theta_{d}\right)=\log\left(\frac{\theta_{d}}{1-\theta_{d}}\right)  =  \boldsymbol{x}_{d}^{T}\boldsymbol{\beta}+u_{d}$

donde $u_{d}\sim N\left(0,\sigma_{u}^{2}\right)$ y $n_{d}$ es el
tamaño de la muestra para el área $d$.

# Consideraciones para el modelo 

Para muestras complejas, surgen dos problemas:

  - Los valores de $Y_d$ no son enteros y se ven afectados por las ponderaciones de la encuesta.
  - La varianza muestral en la distribución binomial no es precisa.

# Propuesta de Carolina Franco. 

- Se introduce un **tamaño de muestra efectivo** $\tilde{n}_d$ y un **número de muestra efectivo de éxitos** $\tilde{Y_d}$ para abordar estos problemas y mantener la estimación directa de la pobreza y su varianza correspondiente.

- Dado lo anterior, es posible suponer que 
$$
\tilde{n}_{d}  \sim  \frac{\check{\theta}_{d}\left(1-\check{\theta}_{d}\right)}{\widehat{Var}\left(\hat{\theta}_{d}\right)}
$$
con $\check{\theta}_{d}$ es una preliminar predicción basada en el modelo para la proporción poblacional, $\hat{\theta}_i$ la estimación directa y $\widehat{Var}(\hat{\theta}_d)$ la estimación de la varianza de muestreo.

- Luego, se asume que $\tilde{n}_{d}$ es proporcional a la varianza ajustada y que $\tilde{Y}_{d}=\tilde{n}_{d}\times\hat{\theta}_{d}$.

# Distribuciones previas 

- Se especifican las distribuciones previas para los parámetros $\boldsymbol{\beta}$ y $\sigma_{u}^{2}$:

  - $\boldsymbol{\beta} \sim N(0,10000)$
  - $\sigma_{u}^{2} \sim IG(0.0001,0.0001)$


# Modelo de área: Rutina en `STAN` 

En este bloque de código vemos la transformación que se realiza sobre los parámetros de entrada. 

```
transformed parameters {
   vector[N1] LP;
   vector[N1] theta;
   real<lower=0> sigma_u;
  
   sigma_u = sqrt(sigma2_u); 
   LP =  X * beta + u;
   theta = inv_logit(LP);
}

```
# Modelo de FH: Rutina en `STAN` 

```
model {
  to_vector(beta) ~ normal(0, 10000);
   u ~ normal(0, sigma_u);
  sigma2_u ~ cauchy(0, 1000);
  for(ii in 1:N1){
  y_effect[ii] ~ binomial(n_effec[ii], theta[ii]);
}
  }

generated quantities {
  real ypred[N2];
  vector[N2] thetaLP;
  vector[N2] LP_pred;
  LP_pred =  Xs * beta;
  thetaLP = inv_logit(LP_pred);

}
  
```


# Procedimiento de estimación

Lectura de la base de datos con las estimaciones directas.

```{r, eval=FALSE}
base_FH <-
readRDS("www/04_FH_Beta_y_Binomial/base_FH_2018.rds") %>%
  select(dam2, pobreza, n_eff_FGV)

base_FH <- full_join(base_FH,
             statelevel_predictors_df, by = "dam2")
```
**Las covariables son las mismas que se emplearon en los modelos anteriores.**  

# Dividir el set de datos. 

El proceso de estimación y predicción se hace por separado dentro de `STAN`

-   Dominios observados.
```{r, eval=FALSE}
data_dir <- base_FH %>% filter(!is.na(T_pobreza))
Xdat <- cbind(inter = 1,data_dir[,names_cov])
```

-   Dominios NO observados.
```{r, eval=FALSE}
data_syn <-
  base_FH %>% anti_join(data_dir %>% select(dam2))
Xs <-  cbind(inter = 1,data_syn[,names_cov])
```

#  Obteniendo parámetros adicionales. 

-   Tamaño de muestra efectivo  $\tilde{n}_d$
```{r, eval=FALSE}
n_effec = round(data_dir$n_eff_FGV)
```

-   Número de muestra efectivo de éxitos $\tilde{Y_d}$
```{r, eval=FALSE}
y_effect  = round((data_dir$pobreza)*n_effec)
```


# Lista de parámetros para `STAN`


```{r, eval=FALSE}
sample_data <- list(
  N1 = nrow(Xdat),   # Observados.
  N2 = nrow(Xs),   # NO Observados.
  p  = ncol(Xdat),       # Número de regresores.
  X  = as.matrix(Xdat),  # Covariables Observados.
  Xs = as.matrix(Xs),    # Covariables NO Observados
  n_effec = n_effec,
  y_effect  = y_effect  # Estimación directa. 
)
```

# Compilando el modelo en `STAN`
  
```{r, eval=FALSE}
fit_FH_binomial <-
  "www/04_FH_Beta_y_Binomial/14FH_binomial.stan"

model_FH_Binomial <- stan(
  file = fit_FH_binomial,  
  data = sample_data,   
  verbose = FALSE,
  warmup = 500,         
  iter = 1000,            
  cores = 4              
)

saveRDS(model_FH_Binomial,
file = "www/04_FH_Beta_y_Binomial/model_FH_Binomial.rds")
```


# Resultados del modelo para los dominios observados. 


```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "PPC modelo de área Binomial"}
knitr::include_graphics("www/04_FH_Beta_y_Binomial/05_Fig_pcc_Bin.PNG")
```

# Análisis gráfico de la convergencia de las cadenas de $\sigma^2_u$. 

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "Recorrido de las cadenas"}
knitr::include_graphics("www/04_FH_Beta_y_Binomial/06_Fig_Sigma_Bin.PNG")
```

# Mapa de pobreza con modelo de área de respuesta binomial 

```{r echo=FALSE, out.width = "500px", out.height="250px", fig.cap= "Mapa de pobreza con el modelo de área de respuesta beta."}
knitr::include_graphics("www/04_FH_Beta_y_Binomial/07_Fig_Mapa_Bin.PNG")
```

# Mapa de los coeficientes de variación para la pobreza

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "Mapa de los coeficientes de variación"}
knitr::include_graphics("www/04_FH_Beta_y_Binomial/08_Fig_Mapa_Bin_cv.PNG")
```

# Modelos de unidad.

# Modelo de unidad para la estimación del ingreso medio

- Esta metodología, conocida como "pseudo-EBP," es un modelo con errores anidados que incorpora los factores de expansión de la encuesta. Este modelo se basa en el concepto del mejor predictor empírico, incorporando información de los microdatos del censo de población.

- A diferencia de otros modelos con errores anidados de Battese, Harter y Fuller (BHF), no requiere conocer o estimar previamente la varianza de los residuos del modelo. Esto hace que la metodología sea más accesible y práctica.

# Mayor Nivel de Desagregación en las Estimaciones

- Bajo ciertas condiciones, estos modelos permiten una mayor desagregación de las estimaciones. Esto significa que podemos generar estimaciones a nivel de municipio, provincia o comuna, desglosadas por diversas características, como autorreconocimiento étnico, grupo de edad, sexo, discapacidad, entre otros, si se cuenta con covariables a nivel de individuo.

# Metodo de estimación del modelo de unidad 

Para estimar el ingreso medio de las personas, es decir, 

$$
\bar{Y}_d = \frac{\sum_{U_d}y_{di}}{N_d}
$$
donde $y_{di}$ es el ingreso de cada personas. Note que, 

$$
\bar{Y}_d =  \frac{\sum_{s_d}y_{di} + \sum_{s^c_d}y_{di}}{N_d} 
$$

# Predicción del modelo de unidad 

El estimador de $\bar{Y}$ esta dado por: 

$$
\hat{\bar{Y}}_d = \frac{\sum_{s_d}y_{di} + \sum_{s^c_d}\hat{y}_{di}}{N_d}
$$
donde

$$\hat{y}_{di}=E_{\mathscr{M}}\left(y_{di}\mid\boldsymbol{x}_{d},\boldsymbol{\beta}\right)$$,

donde $\mathscr{M}$ hace referencia a la medida de probabilidad inducida por el modelamiento. Así tse tiene que: 

$$
\hat{\bar{Y}}_d = \frac{\sum_{U_{d}}\hat{y}_{di}}{N_d}
$$

# Definición del modelo de unidad. 

- Estamos aplicando un modelo bayesiano para predecir el ingreso medio en áreas no observadas. Esto se basa en la suposición de que los ingresos medios $Y_{di}$ siguen una distribución normal con una media $\mu_{di}$ y una varianza $\sigma_e^{2}$.

- La media $\mu_{di}$ se relaciona con las características individuales $\boldsymbol{X}$ a través de un conjunto de parámetros $\boldsymbol{\beta}$, junto con un efecto específico del dominio $u_{d}$ y un término de error de estimación $e_{di}$.

- El modelo: 

  -   $Y_{di} \sim  N\left(\mu_{di},\sigma_e^{2}\right)$
  -   $\mu_{di} = \boldsymbol{x}_{di}^{T}\boldsymbol{\beta}+u_{d}+e_{di}$


# Definición del modelo de unidad. 

- Tanto $u_{d}$ como $e_{di}$ siguen distribuciones normales, con medias de cero y varianzas $\sigma^2_{u}$ y $\sigma^2_{e}$ respectivamente.

- Hemos establecido distribuciones previas no informativas para los parámetros $\beta_k$ y $\sigma^2_y$. Esto significa que asumimos que tenemos poca información previa sobre estos parámetros y, por lo tanto, no les asignamos distribuciones previas específicas.
-   $\beta_k  \sim    N(0, 1000)$
-   $\sigma^2_y \sim  IG(0.0001,0.0001)$


# Lectura de librerias y funciónes de `R`

-   *plot_interaction*: Esta crea un diagrama de lineas donde se estudia la interacción entre las variables, en el caso de presentar un traslape de las lineas se recomienda incluir el interacción en el modelo.

-   *Aux_Agregado*: Esta es función permite obtener estimaciones a diferentes niveles de agregación, toma mucha relevancia cuando se realiza un proceso repetitivo.

```{r, eval=FALSE}
library(rstan)
library(rstanarm)
source("www/05_Mod_Ingreso/01_funtions.R")
```
**Las funciones están diseñada específicamente  para este  proceso**

# Encuesta de hogares estandarizadas 

La base original se recodifica como sigue: 

- Años de estudio (**anoest**) se recodifica como:
  - 1 → Sin educación
  - 2 → 1 - 6 años
  - 3 → 7 - 12 años
  - 4 → Más de 12
  - 98 → No aplica
  - 99 → NS/NR (No sabe/No responde)

- **Sexo** se recodifica como:
  - 1 → Hombre
  - 2 → Mujer

- Autoreconocimiento (**etnia**) se recodifica como:
  - 1 → Indígena
  - 2 → Afrodescendiente
  - 3 → Otro

# Encuesta de hogares estandarizadas 

- **Edad** se recodifica como:
  - 1 → 0 - 14
  - 2 → 15 - 29
  - 3 → 30 - 44
  - 4 → 45 - 64
  - 5 → 65 - más

- Zona urbana/rural (**area**) se recodifica como:
  - 0 → Rural
  - 1 → Urbana
- $logingreso = \log(ingreso)$

# Set de dados de la encuesta 

```{r,eval=FALSE}
encuesta_mrp <- 
  readRDS("www/05_Mod_Ingreso/encuesta_estan.rds")

```

```{r,echo=FALSE}
readRDS("www/05_Mod_Ingreso/01_tabla_encuesta.rds") %>% 
  select(-dam,-ingreso,-lp,-li,-fep)  %>%
  tba(cap = "Encuesta estandarizada")
```


# Histograma suavizado del ingreso 

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "Líena negra distribución normal y Línea azul ingreso suavizado"}
knitr::include_graphics("www/05_Mod_Ingreso/02_Fig_densidad_ing.png")
```

# Creando base con la encuesta agregada

El resultado de agregar la base de dato se muestra a continuación:

```{r, eval=FALSE}
byAgrega <- c("dam", "dam2",  "area", "sexo",
              "anoest", "edad",   "etnia")

encuesta_df_agg <-
  encuesta_mrp %>%
  group_by_at(all_of(byAgrega)) %>%
  summarise(n = n(),
            logingreso = mean(logingreso),
            .groups = "drop") 
```

# Encuesta agregada 
El proceso computacional se optimiza al tener la encuesta agregada. 

```{r,echo=FALSE}
readRDS("www/05_Mod_Ingreso/03_tabla_encuesta_agg.rds") %>% 
  head(5) %>% select(-dam) %>% 
  tba(cap = "Encuesta agregada")
```
Ahora, agregamos las covariables 

```{r, eval=FALSE}
encuesta_df_agg <- 
  inner_join(encuesta_df_agg, statelevel_predictors_df)
```

# Definiendo el modelo multinivel.

Después de haber ordenado la encuesta, podemos pasar a la definición del modelo.

```{r, eval = FALSE}
fit <- stan_lmer(
  logingreso ~    # Log del Ingreso medio (Y)
    (1 | dam2) +  # Efecto aleatorio (ud)
    edad +        # Efecto fijo (Variables X)
    sexo  + tasa_desocupacion +
    luces_nocturnas + cubrimiento_cultivo +
    cubrimiento_urbano ,
  weights = n,   # Número de observaciones.
  data = encuesta_df_agg, # Encuesta agregada
  verbose = TRUE, # Muestre el avance del proceso
  chains = 4, # Número de cadenas.
  iter = 1000) # Número de realizaciones de la cadena
saveRDS(fit, file = "Data/fit_ingresos.rds")
```

# Validación de la convengencia de las cadenas. 

```{r, eval=FALSE}
library(posterior)
library(bayesplot)
p1 <-
  (mcmc_dens_chains(fit, pars = "sigma") +
     mcmc_areas(fit, pars = "sigma")) /
  mcmc_trace(fit, pars = "sigma")
ggsave(p1,
  plot = "www/05_Mod_Ingreso/04_Fig_sigma_ing.png" )
```

# Cadenas para $\sigma^2$ 

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "Recorrido de las cadenas"}
knitr::include_graphics("www/05_Mod_Ingreso/04_Fig_sigma_ing.png")
```


# Distribución posterior de los coeficientes

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "Distribución posterior para los betas"}
knitr::include_graphics("www/05_Mod_Ingreso/05_Fig_beta_ing.png")
```

# Resultados del modelo en la encuesta 

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "PPC para el ingreso"}
knitr::include_graphics("www/05_Mod_Ingreso/06_Fig_Ingreso.PNG")
```

# Resultados del modelo en la encuesta 

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "PPC para el log_ingreso"}
knitr::include_graphics("www/05_Mod_Ingreso/07_Fig_Log_Ingreso.PNG")
```

# Predicción del ingreso con el modelo de unidad

El proceso de predicción inicia con la lectura del censo agregado que fue estandarizada previamente, luego se une con la base de covariables dando como resultado la siguiente tabla. 

```{r, eval=FALSE}
poststrat_df <-
  readRDS("www/05_Mod_Ingreso/censo_dam2.rds") %>% 
   left_join(statelevel_predictors_df)
```


```{r, echo = FALSE}
tabla_poststrat <- readRDS("www/05_Mod_Ingreso/08_tabla_poststrat.rds")
tba( tabla_poststrat %>% select(2:8) %>% head(5),
     cap = "Censo agregado y covariables")
```

# Distribución posterior.

Para obtener una distribución posterior de cada observación se hace uso de la función *posterior_epred* de la siguiente forma.

```{r, eval=FALSE}
epred_mat <- posterior_epred(
  fit, newdata = poststrat_df, 
  type = "response")
```


# Ingreso en términos de lineas de pobreza.

Escribir la estimación del ingreso medio en términos de lineas de pobreza. 

```{r,eval=FALSE}
lp <- encuesta_mrp %>% distinct(area,lp,li))
```


```{r,eval=TRUE,echo=FALSE}
tabla_lp <- 
  readRDS("www/05_Mod_Ingreso/09_tabla_linea_pobreza.rds")
tba(tabla_lp, "Líneas de pobreza")
```

```{r, eval=FALSE}
lp <- inner_join(poststrat_df,lp,by = "area") %>% 
  select(lp)

epred_mat <- (exp(epred_mat)-1)/lp$lp
```

# Estimación del ingreso medio nacional

El proceso se reduce a operaciones matriciales, las cuales están organizadas en la función _*Aux_Agregado*_

```{r, eval=FALSE}
mrp_estimate_Ingresolp <-
  Aux_Agregado(poststrat = poststrat_df,
             epredmat = epred_mat,
             byMap = NULL)

```

```{r, echo=FALSE}
tabla_est <- 
  readRDS("www/05_Mod_Ingreso/10_tabla_estimacion.rds")
tba(tabla_est$mrp_estimate_Ingresolp, 
    cap =  "Estimación de ingreso medio nacional")
```

# Estimación del ingreso medio dam2

De forma similar es posible obtener los resultados para las divisiones administrativas. 

```{r, eval=FALSE}
mrp_estimate_dam2 <-
  Aux_Agregado(poststrat = poststrat_df,
             epredmat = epred_mat,
             byMap = "dam2")
```

```{r,echo=FALSE}
tba(tabla_est$mrp_estimate_dam2 %>% head(5),
    cap =  "Estimación por división administrativas." )
```

# Mapa del ingreso medio con el modelo de unidad

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "Mapa de ingreso medio con el modelo de unidad"}
knitr::include_graphics("www/05_Mod_Ingreso/11_Fig_Mapa_COL.PNG")
```

# Estimación de la pobreza a partir del ingreso

Sea 
$$
y_{ji}=\begin{cases}
1 & ingreso_{ji}\le lp\\
0 & e.o.c.
\end{cases}
$$ 
donde $ingreso_{ji}$ representa el ingreso de la $i$-ésima persona en el $j$-ésimo post-estrato y $lp$ es un valor limite, en particular la linea de pobreza. 

```{r, eval=FALSE}
epred_mat_pobreza_lp <- (exp(epred_mat)-1) <= lp$lp
```

# Estimación de la pobreza

El proceso se simplifica aplicando la función anterior. 

```{r, eval=FALSE}
(mrp_estimate_Ingresolp <-
  Aux_Agregado(poststrat = poststrat_df,
             epredmat = epred_mat_pobreza_lp,
             byMap = NULL)
)
```

```{r, echo=FALSE}
tabla_est_pobreza <- 
  readRDS("www/05_Mod_Ingreso/12_tabla_pobreza.rds")
tba(tabla_est_pobreza$mrp_estimate_Ingresolp, 
    cap =  "Estimación de la pobreza")
```


# Estimación del pobreza por dam2

De forma similar es posible obtener los resultados para las divisiones administrativas. 

```{r, eval=FALSE}
mrp_estimate_dam2 <-
  Aux_Agregado(poststrat = poststrat_df,
             epredmat = epred_mat,
             byMap = "dam2")
```

```{r,echo=FALSE}
tba(tabla_est_pobreza$mrp_estimate_dam2 %>% head(5),
    cap =  "Estimación por división administrativas." )
```

# Mapa de pobreza por el modelo de unidad

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "Mapa de la pobreza a partir ingreso medio"}
knitr::include_graphics("www/05_Mod_Ingreso/13_Fig_Mapa_COL_Pobreza.PNG")
```

# Modelo de unidad para la estimación de la pobreza

- La regresión logística se usa cuando la variable dependiente es binaria, ya que permite estimar la probabilidad del evento estudiado.

- Para obtener estimaciones de probabilidad, se realiza una transformación logarítmica conocida como _logit_.

- El logit se calcula como el logaritmo de la probabilidad de éxito dividido por la probabilidad de fracaso:

$$\ln\left(\frac{\theta}{1-\theta}\right)$$

donde $\theta$ es la probabilidad de éxito.

# Modelo de unidad con respuesta binaria
  - Se emplea un modelo de regresión logística de efectos aleatorios para relacionar la expectativa $\theta_{ji}$ de esta variable con covariables disponibles $x_{ji}$ y el efecto aleatorio $u_d$.

  - El modelo se expresa como: 
  $\ln\left(\frac{\theta_{ji}}{1-\theta_{ji}}\right) = \boldsymbol{x}_{ji}^{T}\boldsymbol{\beta}+u_d$.

  - Los coeficientes $\boldsymbol{\beta}$ son los efectos fijos de las variables sobre las probabilidades, y $u_d$ son efectos aleatorios.

# Distribuciones Previas

Las distribuciones previas son no informativas y se asumen como:
- $\beta_k \sim N(0, 1000)$.
- $\sigma^2_u \sim IG(0.0001, 0.0001)$.

# Proceso de estimaión

  - Estimar la proporción de personas por debajo de la línea de pobreza: $P_d = \frac{\sum_{U_d}y_{di}}{N_d}$.

  - El estimador se calcula como: $\hat{P} = \frac{\sum_{s_d}y_{di} + \sum_{s^c_d}\hat{y}_{di}}{N_d}$.
  - Donde $\hat{y}_{di}$ es el valor esperado de $y_{di}$ bajo el modelo.


# Estimación en R

El proceso inicia con la definición de la pobreza haciendo uso de la línea de pobreza definida en CEPAL así 

```{r, eval=FALSE}
encuesta_mrp %<>% mutate( 
pobreza = ifelse(ingreso < lp,1,0))
```


# Creando base con la encuesta agregada

En forma similar al modelo del ingreso, ahora se realiza un conteo de las personas que están por debajo de la linea de pobreza agregando por algunas variables.

```{r, eval=FALSE}
encuesta_df_agg <-
  encuesta_mrp %>%       # Encuesta  
  group_by_at(all_of(byAgrega)) %>%   
  summarise(n = n(), # Número de observaciones
  # conteo de personas con características similares.           
       pobreza = sum(pobreza),
       no_pobreza = n-pobreza,
      .groups = "drop") %>%     
  arrange(desc(pobreza))                    # Ordenar la base.
```


# Tabla agregada 

El resultado de agregar la base de dato se muestra a continuación:

```{r, echo=FALSE}
readRDS("www/06_Mod_Pobreza/01_tabla_agg_pobreza.rds") %>% 
  head(5) %>% select(-dam,-n) %>% 
tba(cap = "Conteo de personas en condición de pobreza")
```

Ahora incorporan las covariables. 
```{r, eval=FALSE}
encuesta_df_agg %<>%
  inner_join(statelevel_predictors_df)
```

# Modelo de unidad en `STAN`

Después de haber ordenado la encuesta, podemos pasar a la definición del modelo.

```{r, eval = FALSE}
fit <- stan_glmer(
  cbind(pobreza, no_pobreza) ~                              
    (1 | dam2) +    # Efecto aleatorio (ud)
    edad +          # Efecto fijo (Variables X)
    sexo  + tasa_desocupacion +
    luces_nocturnas + cubrimiento_cultivo +
    cubrimiento_urbano ,
    data = encuesta_df_agg, # Encuesta agregada 
    verbose = TRUE,   # Muestre el avance del proceso
    chains = 4,       # Número de cadenas.
    iter = 100, cores = 4,
    family = binomial(link = "logit")
                )
saveRDS(fit, file = "www/06_Mod_Pobreza/fit_pobreza.rds")

```

# Distribución posterior de los coeficientes 

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "Dictribución posterior de los coeficientes"}
knitr::include_graphics("www/06_Mod_Pobreza/02_Fig_posterior_coef.png")
```


# Seguimiento de las cadenas para los coeficientes

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "Cadenas de los coeficientes"}
knitr::include_graphics("www/06_Mod_Pobreza/03_Fig_posterior_coef_cadena.png")
```


# Resultados del modelo en la encuesta 

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "PPC para el ingreso"}
knitr::include_graphics("www/06_Mod_Pobreza/04_Fig_ppc_pobreza.PNG")
```

# Predicción del pobreza con el modelo de unidad

El proceso de predicción inicia con la lectura del censo agregado que fue estandarizada previamente, luego se une con la base de covariables dando como resultado la siguiente tabla. 

```{r, eval=FALSE}
poststrat_df <-
  readRDS("www/06_Mod_Pobreza/censo_dam2.rds") %>% 
   left_join(statelevel_predictors_df)
```


```{r, echo = FALSE}
tabla_poststrat <- readRDS("www/06_Mod_Pobreza/05_tabla_poststrat.rds")
tba( tabla_poststrat %>% select(2:8) %>% head(5),
     cap = "Censo agregado y covariables")
```

# Distribución posterior.

Para obtener una distribución posterior de cada observación se hace uso de la función *posterior_epred* de la siguiente forma.

```{r, eval=FALSE}
epred_mat <- posterior_epred(
  fit, newdata = poststrat_df, 
  type = "response")
```

# Estimación de la tasa de pobreza

De forma similar al modelo de ingreso se hace uso de la función *Aux_Agregado* para tener las estimaciones de tasa de pobreza. 
```{r, echo=FALSE}
tablas_pobreza <- readRDS("www/06_Mod_Pobreza/tablas.rds")
```


```{r, eval=FALSE}
(mrp_estimate_Ingresolp <-
  Aux_Agregado(poststrat = poststrat_df,
             epredmat = epred_mat,
             byMap = NULL)
) %>% tba()
```

```{r, echo=FALSE}
mrp_estimate_Ingresolp <- tablas_pobreza$mrp_estimate_Ingresolp
tba(mrp_estimate_Ingresolp, "Estimación de la tasa de pobreza")
```

# Estimación de la tasa de pobreza por dam2

De forma similar es posible obtener los resultados para las divisiones administrativas del país.  

```{r, eval=FALSE}
mrp_estimate_dam2 <-
  Aux_Agregado(poststrat = poststrat_df,
             epredmat = epred_mat,
             byMap = "dam2")
```

```{r, echo=FALSE}
mrp_estimate_dam2 <- tablas_pobreza$mrp_estimate_dam2
tba(mrp_estimate_dam2 %>% head(5) )
```

# Mapa de pobreza estimado con el modelo de unidad 

```{r echo=FALSE, out.width = "400px", out.height="250px", fig.cap= "Mapa de la pobreza modelo de unidad"}
knitr::include_graphics("www/06_Mod_Pobreza/06_Fig_Map_COL.PNG")
```

# Modelo de unidad Índice de Privación Multidimensional (IPM)
 

# Introducción

- La pobreza es un tema crucial en la agenda nacional e internacional, como lo demuestra el primer objetivo de la agenda 2030 para el Desarrollo Sostenible.
- Tradicionalmente, se mide la pobreza de manera unidimensional, basada en ingresos y gastos.
- Abordar la pobreza desde una perspectiva multidimensional permite capturar una gama más amplia de factores que afectan la calidad de vida.

# Índice de Pobreza Multidimensional (IPM)

- El IPM es una medida que evalúa la pobreza considerando múltiples dimensiones de bienestar.
- Se calcula mediante ponderaciones y umbrales en función de diferentes indicadores de calidad de vida.
- El IPM es una variante de la metodología FGT (Foster, Greer y Thorbecke, 1984) utilizada para medir la pobreza unidimensional.

# Ecuación del IPM 

- Se expresa como un promedio de puntuación de privación censurada, como se detalla en las siguientes ecuaciones:

$$
IPM = \frac{1}{N}\sum_{i=1}^{N}c_i(z)
$$

Donde:
- $N$ es el número de individuos u hogares en la población.
- $c_i(z)$ es el puntaje de privación censurado de la observación $i$. 

# Calculo de $c_i(z)$ 
La forma de obtener $c_i(z)$  esta dado por la siguiente ecuación:

- Si $q_i\ge z$ entonces  $c_{i}$ será igual a $q_i$
- Si $q_i < z$ entonces  $c_{i}$ será igual a $0$

Con:
- $q_i =  \sum_{k=1}^{K} w_k \cdot y_{i}^{k}$, donde $K$ es el número de dimensiones o indicadores de la privación, $w_k$ es el ponderador asociado a la dimensión $k$, y $y_{i}^{k}$ es una variable binaria.

# Componentes del IPM:

1. **Headcount Ratio (H):**

   - Mide la proporción de personas privadas en al menos una dimensión de pobreza.
   - Se calcula como el número de personas privadas en al menos una dimensión sobre la población total.
   -    $H = \frac{1}{N} \sum_{i=1}^{N} I\left( q_{i} \ge z \right)= \frac{N\left(z\right)}{N}$ donde $N\left(z\right) =  \sum_{i=1}^{N} I\left( q_{i} \ge z \right)$

2. **Intensity of Deprivation (A):**

   - Mide la intensidad promedio de privación entre las personas privadas.
   - Se calcula como el promedio de los indicadores de privación para aquellas personas que están privadas en al menos una dimensión.
   - $A=\sum_{i=1}^{N}\frac{c_{i}\left(z\right)}{N\left(z\right)}$
   

# Cálculo del IPM apartir de H y A

- El IPM se obtiene multiplicando los valores de H y A.
- Matemáticamente, se expresa como el promedio de puntuación de privación censurada.


$$
IPM=\frac{N\left(z\right)}{N}\times\sum_{i=1}^{N}\frac{c_{i}\left(z\right)}{N\left(z\right)}=\frac{1}{N}\sum_{i=1}^{N}c_{i}\left(z\right)
$$

# Modelo de unidad para el IPM

- En muchas aplicaciones, la variable de interés en áreas pequeñas es binaria, es decir, $y_{dj}$ toma valores de 0 o 1, representando la ausencia o presencia de una característica específica.

- El objetivo de estimación en cada dominio $d = 1,\cdots , D$ es la proporción $\theta_d =\frac{1}{N_d}\sum_{i=1}^{N_d}y_{di}$ de la población que presenta esta característica.


- El logit de $\theta_{di}$ se define como 
$$
\ln \left(\frac{\theta_{di}}{1-\theta_{di}}\right) = \eta_{di} =  \boldsymbol{x}_{di}^{T}\boldsymbol{\beta} + u_{d}
$$

donde $\boldsymbol{\beta}$ es un vector de parámetros de efecto fijo y $u_d$ es un efecto aleatorio específico del área para el dominio $d$ con $u_d \sim N\left(0,\sigma^2_u \right)$.


# Modelo de unidad para el IPM


- Los $u_d$ son independientes, y $y_{di}\mid u_d \sim Bernoulli(\theta_{di})$ con $E(y_{di}\mid u_d)=\theta_{di}$ y $Var(y_{di}\mid u_d)=\sigma_{di}^2=\theta_{di}(1-\theta_{di})$.
- $\boldsymbol{x}_{di}^T$ representa un vector de $p\times 1$ de valores de $p$ variables auxiliares.

- Entonces, $\theta_{di}$ se puede expresar como: 

$$
\theta_{di} = \frac{\exp(\boldsymbol{x}_{di}^T\boldsymbol{\beta} + u_{d})}{1+ \exp(\boldsymbol{x}_{di}^T\boldsymbol{\beta} + u_{d})}
$$

**El modelo se estima para cada dimensión.**

# Distribuciones previas

Como es tradicional se usan distribuciones previas no informativas

- $\beta_k  \sim    N(0, 10000)$

- $\sigma^2_u \sim  IG(0.0001,0.0001)$


# Estimación del IPM usando los modelos de unidad 

- Estimar la proporción de personas que presentan la $k-$ésima carencia, es decir, $P_d = \frac{\sum_{U_d}c_{di}(z)}{N_d}$.
- El estimador de $P$ se calcula como:

$$
\hat{P}_d = \frac{\sum_{s_d}c_{di}(z) + \sum_{s^c_d}\hat{c}_{di}(z)}{N_d}
$$

donde $\hat{c}_{di}(z)$ se define como:

- Si $\hat{q}_{di}\ge z$ entonces  $c_{di}$ será igual a $\hat{q}_{di}$
- Si $\hat{q}_{di} < z$ entonces  $c_{di}$ será igual a $0$


# Estimación de $q_{di}$

La estimación de $\hat{q}$ esta dada por  

$$
\hat{q}_{di} =  \sum_{k=1}^{K} w_k \cdot \hat{y}_{di}^{k}  
$$

donde

$$
\hat{y}_{di}^{k}=E_{\mathscr{M}}\left(y_{di}^{k}\mid\boldsymbol{x}_{d},\boldsymbol{\beta}\right)
$$

- Así, se obtiene el estimador de $P$ para cada dominio $d$.




# ¡Gracias!

::: yellow
*Email*: [andres.gutierrez\@cepal.org](mailto:andres.gutierrez@cepal.org){.email}
:::